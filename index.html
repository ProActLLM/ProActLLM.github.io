<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ProActLLM</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
    
<div class="header-bg">
  <nav>
    <button class="nav-toggle" onclick="toggleNav()">
      <span></span>
      <span></span>
      <span></span>
    </button>
    <div class="nav-links">
      <a href="#about">About</a>
      <a href="#cfp">CFP</a>
      <a href="#submission">Submission</a>
      <a href="#dates">Dates</a>
      <a href="#camera-ready">Camera-Ready</a>
      <!-- <a href="#program">Program</a> -->
      <a href="#speakers">Speakers</a>
      <a href="#organizers">Organizers</a>
      <a href="#committee">Committee</a>
      <a href="#contact">Contact</a>
    </div>
  </nav>

  <header>
    <h1>ProActLLM</h1>
    <h2>Proactive Conversational Information Seeking with Large Language Models</h2>
    <p>
      November 14, 2025<br>
      Coex, Seoul, South Korea (co-located with CIKM 2025)
    </p>
  </header>
</div>

<main>

  <section id="about" class="section">
    <h2>About</h2>

    <h3>From Reactive to Proactive: The Next Frontier in Conversational AI</h3>
    <p>While today's AI assistants excel at answering direct questions, they remain fundamentally reactive‚Äîwaiting for users to ask before they act. What if conversational AI could anticipate your needs, offer timely suggestions, and guide you toward information you actually need or didn't even know you needed?</p>
    <p>ProActLLM explores this transformative shift from reactive question-answering to proactive information-seeking assistants powered by Large Language Models (LLMs). Our workshop investigates how AI systems can:</p>
    <ul>
      <li>Anticipate user needs before they're explicitly expressed</li>
      <li>Model complex conversational context to understand deeper intent</li>
      <li>Take helpful initiative while respecting user control</li>
      <li>Seamlessly integrate external tools and knowledge sources</li>
      <li>Personalize interactions based on individual preferences and expertise</li>
      <li>Adapt and learn from user feedback over time</li>
      <li>Optimise interaction interfaces and response representations for engaging user experience</li>
    </ul>

    <h3>Why This Matters Now</h3>
    <p>Recent advances in LLMs have opened unprecedented opportunities for building truly intelligent, context-aware dialogue systems. Yet current conversational AI largely remains stuck in a reactive paradigm. ProActLLM addresses this gap by bringing together leading researchers from Natural Language Processing, Information Retrieval, Human-Computer Interaction, and Cognitive Science to define and advance this emerging field.</p>

    <h3>Our Vision</h3>
    <p>We envision conversational assistants that don't just respond ‚Äî they collaborate. Systems that understand not only what you're asking, but what you're trying to achieve. Assistants that can surface relevant information at the right moment, suggest productive next steps, and adapt their behavior to your expertise level and cognitive load.
      Join us in shaping the future of proactive conversational AI ‚Äî where the conversation truly becomes a partnership between human intelligence and artificial intelligence.</p>
  </section>

  <section id="cfp" class="section">
    <h2>Call for Papers</h2>

    <h3>Shape the Future of Proactive Conversational AI</h3>
    <p>We invite original research papers (short and long), perspective papers, system demonstrations, and resource papers that advance our understanding of proactive conversational information seeking. Whether you're developing novel algorithms, discussing potential related future research directions, proposing evaluation frameworks, or building real-world applications, we want to hear from you.</p>

    <h3>Research Themes</h3>
    <h4>ü§ñ Core Proactive Behaviors</h4>
    <ul>
      <li><strong>Proactive question asking and clarification:</strong> How can agents formulate the right questions at the right time to better understand user intent?</li>
      <li><strong>Mixed-initiative dialogue management:</strong> What models best balance system initiative with user control in information-seeking conversations?</li>
      <li><strong>Anticipatory information retrieval:</strong> Techniques for predicting and surfacing relevant information before users explicitly request it.</li>
    </ul>
    <h4>üß† Understanding Users and Context</h4>
    <ul>
      <li><strong>User modeling and context understanding:</strong> Inferring user goals, knowledge, expertise levels, and preferences to drive intelligent proactive actions.</li>
      <li><strong>Personalized conversational search:</strong> Adapting search results, suggestions, and dialogue flow based on individual user characteristics, history, and preferences.</li>
      <li><strong>Cognitive load management:</strong> Designing systems that respect users' cognitive capacity and attention limitations while maximizing utility.</li>
      <li><strong>Metacognitive awareness:</strong> Building systems that recognize when users need different types of cognitive support or are experiencing confusion.</li>
    </ul>
    <h4>üîß Technical Foundations</h4>
    <ul>
      <li><strong>LLMs for conversational information access:</strong> Retrieval-augmented generation, knowledge grounding, and dynamic topic suggestion in dialogue.</li>
      <li><strong>Memory and forgetting models:</strong> Human-like memory mechanisms that prioritize, decay, and reconstruct information for better proactive suggestions.</li>
      <li><strong>Tool orchestration and API integration:</strong> Seamlessly coordinating multiple external tools and services for complex, multi-step information needs.</li>
    </ul>
    <h4>üìä Evaluation and Methodology</h4>
    <ul>
      <li><strong>Evaluation metrics and methodologies:</strong> Novel benchmarks and user-centric evaluation protocols for measuring proactive system effectiveness.</li>
      <li><strong>Explainability and transparency:</strong> Making proactive decisions interpretable and helping users understand system reasoning.</li>
      <li><strong>Long-term interaction studies:</strong> Understanding how proactive behaviors affect user satisfaction and task success over time.</li>
    </ul>
    <h4>üåç Applications and Impact</h4>
    <ul>
      <li><strong>Domain-specific applications:</strong> Healthcare, education, customer support, enterprise search, personal assistants, and beyond.</li>
      <li><strong>Multi-modal proactive assistance:</strong> Integrating visual, audio, and textual cues across different interaction modalities.</li>
      <li><strong>Cultural and linguistic adaptation:</strong> Developing systems sensitive to diverse cultural contexts and communication styles.</li>
    </ul>
    <h4>‚öñÔ∏è Responsible AI</h4>
    <ul>
      <li><strong>Ethical and user experience considerations:</strong> Ensuring proactive behavior is helpful rather than intrusive.</li>
      <li><strong>Privacy and fairness:</strong> Protecting user data while ensuring equitable experiences across diverse user populations.</li>
      <li><strong>Bias mitigation:</strong> Addressing and preventing harmful biases in proactive suggestions and recommendations.</li>
    </ul>

    <h3>What We're Looking For</h3>
    <ul>
      <li><strong>Novel Research:</strong> Cutting-edge algorithms, models, and techniques that advance the state-of-the-art in proactive conversational systems</li>
      <li><strong>Practical Systems:</strong> Working implementations, demos, and case studies showing real-world applications of proactive conversational AI</li>
      <li><strong>Theoretical Insights:</strong> Position papers, surveys, and conceptual frameworks that help define and structure this emerging field</li>
      <li><strong>Evaluation Studies:</strong> User studies, benchmarks, and evaluation frameworks that help us better understand and measure proactive behaviors</li>
      <li><strong>Interdisciplinary Perspectives:</strong> Work that bridges computer science with cognitive science, psychology, linguistics, or domain expertise</li>
    </ul>
  </section>

  <blockquote>
    Ready to contribute to the future of conversational AI? We can't wait to see your innovative ideas for making AI assistants truly proactive partners in information seeking.
  </blockquote>

  <section id="submission" class="section">
    <h2>Submission Instructions</h2>
    <p>We welcome original research contributions that advance the field of proactive conversational information seeking. All submissions must be previously unpublished work, not currently under review at another venue.</p>
    
    <h3>Submission Types & Requirements</h3>
    <h4>üìÑ Research Papers</h4>
    <p>
      <strong>Short Papers (5-7 pages):</strong> Preliminary results, novel ideas, or focused contributions.<br>
      <strong>Long Papers (10-12 pages):</strong> Comprehensive technical papers presenting novel algorithms, models, empirical studies, or theoretical insights.
    </p>

    <h4>üìù Perspective Papers (5-12 pages)</h4>
    <p>Opinion pieces, surveys, or conceptual frameworks that help define and structure the field.</p>

    <h4>üñ•Ô∏è System Demonstrations (5-7 pages + demo)</h4>
    <p>Working systems with accompanying demonstration videos (max 5 minutes).</p>

    <h4>üìä Dataset & Resource Papers (5-12 pages)</h4>
    <p>Novel datasets, benchmarks, or evaluation resources for proactive conversational systems</p>

    <p><i>All page limits exclude references and appendices</i></p>

    <h3>Format Requirements</h3>
    <ul>
      <li><strong>Template:</strong> CEUR-WS single-column format</li>
      <li><strong>Language:</strong> English</li>
      <li><strong>File Format:</strong> PDF only</li>
      <li><strong>Submission Portal:</strong> <a href="https://easychair.org/conferences?conf=proactllm2025" target="_blank">https://easychair.org/conferences?conf=proactllm2025</a></li>
      <li><strong>Download Templates:</strong>
        <ul>
          <li><a href="https://ceur-ws.org/Vol-XXX/CEURART.zip" target="_blank" rel="noopener noreferrer">Zip file containing ODT and LaTeX files</a></li>
          <li><a href="https://www.overleaf.com/latex/templates/template-for-submissions-to-ceur-workshop-proceedings-ceur-ws-dot-org/hpvjjzhjxzjk" target="_blank" rel="noopener noreferrer">Overleaf LaTeX CEUR Template (Recommended)</a></li>
        </ul>
      </li>
    </ul>

    <h4>Template Usage Instructions:</h4>
    <ul>
      <li><strong>LaTeX users:</strong> Use the 1-column CEUR-WS LaTeX template (preferred option). Requires TeX-Live 2020 or later for local installations.</li>
      <li><strong>LibreOffice users:</strong> Use the ODT template if you cannot use LaTeX. Ensure Libertinus font family is installed on your computer (instructions included in template).</li>
      <li><strong>Important:</strong> Do <u>not</u> use cloud-based editors (Office 365, Google Docs) as they don't support required fonts.</li>
      <li><strong>Microsoft Word:</strong> Not recommended due to PDF compatibility issues.</li>
      <li><strong>Note:</strong> All templates include the mandatory AI declaration section as of 2024.</li>
    </ul>

    <h3>Submission Guidelines</h3>
    <h4>What to Include</h4>
    <ul>
      <li>Clear problem statement and motivation</li>
      <li>Comprehensive related work positioning within existing literature</li>
      <li>Detailed methodology with sufficient implementation details</li>
      <li>Rigorous evaluation with appropriate baselines and statistical tests</li>
      <li>Honest discussion of limitations and future work</li>
    </ul>
    <h4>Special Requirements by Type</h4>
  <ul>
    <li><strong>Experimental Papers:</strong>
      <ul>
        <li>Include statistical significance testing</li>
        <li>Provide implementation details for reproducibility</li>
        <li>Share code/data when possible (anonymized links acceptable)</li>
      </ul>
    </li>
    <li><strong>System Papers:</strong>
      <ul>
        <li>Include architecture diagrams and technical specifications</li>
        <li>Provide demo video for system demonstrations</li>
        <li>Discuss scalability and real-world deployment considerations</li>
      </ul>
    </li>
    <li><strong>Position Papers:</strong>
      <ul>
        <li>Clearly articulate the position or perspective</li>
        <li>Support arguments with evidence from literature</li>
        <li>Discuss implications for future research directions</li>
      </ul>
    </li>
  </ul>
  </section>

  <section id="camera-ready" class="section">
    <h2>Camera-Ready Instructions</h2>
    
    <h3>For accepted papers:</h3>
    <ul>
      <li>Address all reviewer comments and concerns</li>
      <li>Follow <strong>CEUR-WS single-column format</strong> exactly</li>
      <li>Ensure compliance with <strong>CEUR-WS publication requirements</strong></li>
      <li>Submit source files (<strong>LaTeX preferred</strong>) along with PDF</li>
      <li>Complete <strong>CEUR-WS copyright agreement</strong></li>
    </ul>

    <p><strong>Publication:</strong> Accepted papers will be published in CEUR Workshop Proceedings (CEUR-WS.org), which is indexed by DBLP and Scopus.</p>
  </section>

  <blockquote>
    We're excited to see your contributions to the future of proactive conversational AI!
  </blockquote>
  
  <section id="dates" class="section">
    <h2>Important Dates</h2>
    <div class="dates-table">
      <table>
        <tbody>
          <tr>
            <td><strong>Paper Submission Deadline:</strong></td>
            <td><s>August 31, 2025</s> September 15, 2025 (11:59 PM AoE)</td>
          </tr>
          <tr>
            <td><strong>Notification of Acceptance:</strong></td>
            <td>September 30, 2025</td>
          </tr>
          <tr>
            <td><strong>Camera-Ready Deadline:</strong></td>
            <td>October 10, 2025 (11:59 PM AoE)</td>
          </tr>
          <tr>
            <td><strong>Workshop Date:</strong></td>
            <td>November 14, 2025</td>
          </tr>
        </tbody>
      </table>
    </div>
  </section>

  <section id="speakers" class="section">
    <h2 class="non-text-section-header">Keynote Speaker</h2>
    <div class="keynote-speaker">
      <div class="person">
        <a href="#" target="_blank" rel="noopener">
          <img src="assets/images/tba.png" alt="TBA" />
          <p>TBA<br><em>To Be Announced</em></p>
        </a>
      </div>
      <div class="bio">
        <p>
        The keynote speaker's bio will be announced soon.
        </p>
      </div>
    </div>
  </section>

  <!-- <section id="program" class="section">
    <h2 class="non-text-section-header">Program</h2>
    <div class="program-table">
      <table>
        <thead>
          <tr>
            <th>Time</th>
            <th>Activity</th>
            <th>Details</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>09:00 - 09:15</td>
            <td>Opening & Welcome</td>
            <td>Workshop introduction and overview</td>
          </tr>
          <tr>
            <td>09:15 - 10:15</td>
            <td>Keynote Talk</td>
            <td>TBA</td>
          </tr>
          <tr>
            <td>10:15 - 10:45</td>
            <td>Coffee Break</td>
            <td>Networking and discussions</td>
          </tr>
          <tr>
            <td>10:45 - 12:00</td>
            <td>Paper Presentations</td>
            <td>Selected paper presentations</td>
          </tr>
          <tr>
            <td>12:00 - 13:30</td>
            <td>Lunch Break</td>
            <td>Lunch and networking</td>
          </tr>
          <tr>
            <td>13:30 - 15:00</td>
            <td>Panel Discussion</td>
            <td>Future directions and challenges</td>
          </tr>
          <tr>
            <td>15:00 - 15:30</td>
            <td>Coffee Break</td>
            <td>Networking and discussions</td>
          </tr>
          <tr>
            <td>15:30 - 17:00</td>
            <td>Interactive Session</td>
            <td>Hands-on activities and demos</td>
          </tr>
          <tr>
            <td>17:00 - 17:15</td>
            <td>Closing</td>
            <td>Wrap-up and next steps</td>
          </tr>
        </tbody>
      </table>
    </div>
  </section> -->

  <section id="organizers" class="section">
    <h2 class="non-text-section-header">Organizers</h2>
    <div class="organizers">
      <div class="person">
        <a href="https://shubham-chatterjee-mst.github.io/" target="_blank" rel="noopener">
          <img src="assets/images/shbham_chatterjee.jpg" alt="Shubham Chatterjee" />
          <p>Shubham Chatterjee<br><em>Missouri S&T, USA</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://www.xiwangeric.com/" target="_blank" rel="noopener">
          <img src="assets/images/xi_wang.jpg" alt="Xi Wang" />
          <p>Xi Wang<br><em>University of Sheffield, UK</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://imsure318.github.io/" target="_blank" rel="noopener">
          <img src="assets/images/shuo_zhang.jpg" alt="Shuo Zhang" />
          <p>Shuo Zhang<br><em>Bloomberg, UK</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://sadjadeb.github.io/" target="_blank" rel="noopener">
          <img src="assets/images/sajad_ebrahimi.png" alt="Sajad Ebrahimi" />
          <p>Sajad Ebrahimi<br><em>University of Guelph, Canada</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://renzhaochun.github.io/" target="_blank" rel="noopener">
          <img src="assets/images/zhaochun_ren.jpeg" alt="Zhaochun Ren" />
          <p>Zhaochun Ren<br><em>Leiden University, Netherlands</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://gdebasis.github.io/" target="_blank" rel="noopener">
          <img src="assets/images/debasis_ganguly.jpg" alt="Debasis Ganguly" />
          <p>Debasis Ganguly<br><em>University of Glasgow, UK</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://www.computing.dcu.ie/~gjones/" target="_blank" rel="noopener">
          <img src="assets/images/gareth_jones.jpg" alt="Gareth Jones" />
          <p>Gareth Jones<br><em>Dublin City University, Ireland</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://sites.google.com/site/emineyilmaz/" target="_blank" rel="noopener">
          <img src="assets/images/emine_yilmaz.jpg" alt="Emine Yilmaz" />
          <p>Emine Yilmaz<br><em>University College London, UK</em></p>
        </a>
      </div>
      <div class="person">
        <a href="https://groups.cs.umass.edu/zamani/" target="_blank" rel="noopener">
          <img src="assets/images/hamed_zamani.jpg" alt="Hamed Zamani" />
          <p>Hamed Zamani<br><em>UMass Amherst, USA</em></p>
        </a>
      </div>
    </div>
  </section>

  <!-- <section id="committee" class="section">
    <h2>Program Committee</h2>
    <ul class="committee-list">
      <li><strong>Name</strong> - <em>Affiliation</em></li>
      <li><strong>Name</strong> - <em>Affiliation</em></li>
      <li><strong>Name</strong> - <em>Affiliation</em></li>
      <li><strong>Name</strong> - <em>Affiliation</em></li>
      <li><strong>Name</strong> - <em>Affiliation</em></li>
      <li><strong>Name</strong> - <em>Affiliation</em></li>
    </ul>
    <p><em>More committee members to be announced...</em></p>
  </section> -->

  <section id="contact" class="section">
    <h2>Contact</h2>
    <p>Email us at <a href="mailto:shubham.chatterjee@mst.edu">shubham.chatterjee@mst.edu</a>, <a href="mailto:xi.wang@sheffield.ac.uk">xi.wang@sheffield.ac.uk</a></p>
  </section>

</main>

<footer>
  <p>¬© 2025 ProActLLM Workshop</p>
</footer>

<script>
function toggleNav() {
  const navLinks = document.querySelector('.nav-links');
  navLinks.classList.toggle('active');
}
</script>

</body>
</html>
